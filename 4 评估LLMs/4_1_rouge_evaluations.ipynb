{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9qSUZeT06otkFqZ1eYrwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masterlyj/self-LLM_Agent_RL/blob/main/4%20%E8%AF%84%E4%BC%B0LLMs/4_1_rouge_evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 大语言模型项目"
      ],
      "metadata": {
        "id": "NvoxCOtc0zkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 大语言模型策略的应用与实现"
      ],
      "metadata": {
        "id": "cSQd_Fk303Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 - BLEU, ROUGE 和 N-Grams"
      ],
      "metadata": {
        "id": "4EB5-Pp701hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 ROUGE 评估摘要质量"
      ],
      "metadata": {
        "id": "lWeszF2k062z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **模型**: t5-base-cnn / t5-base\n",
        "- **Colab 环境**: CPU\n",
        "- **关键词**: 摘要评估, N-Grams, ROUGE\n",
        "\n",
        "**相关背景**:\n",
        "\n",
        "评估大语言模型（LLM）的方式与评估传统机器学习模型（如回归或分类）截然不同。在传统 ML 中，我们常用准确率（Accuracy）、F1 分数或召回率（Recall）。\n",
        "生成式语言任务的指标是独特的。根据具体应用场景，我们会选择不同的指标来评估模型性能。\n",
        "在本笔记本中，我们将探索使用 **ROUGE** 指标来衡量语言模型生成的摘要质量。"
      ],
      "metadata": {
        "id": "2afKq1cK084r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 什么是 ROUGE?"
      ],
      "metadata": {
        "id": "axUHXb7n1HMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "ROUGE 并非单一指标，而是一组指标的集合，用于衡量**生成摘要**与作为基准的**参考摘要**之间的重叠度和相似性。\n",
        "\n",
        "它通常返回四个单独的指标：\n",
        "\n",
        "* **ROUGE-1**: 衡量一元组（Unigrams，即单个词或字）的重叠情况。\n",
        "* **ROUGE-2**: 衡量二元组（Bigrams，即相邻双词）的重叠情况。\n",
        "* **ROUGE-L**: 衡量最长公共子序列（Longest Common Subsequence），奖励生成摘要和参考摘要之间更长的连续一致序列。\n",
        "* **ROUGE-LSUM**: 计算方式是将最长公共子序列的长度除以生成摘要和参考摘要长度之和。"
      ],
      "metadata": {
        "id": "y2nZJQA31GCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 我们要在这个项目中做什么？\n",
        "\n"
      ],
      "metadata": {
        "id": "Z88ugUYl1KNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们将使用两个 T5 模型：一个是原始的 `t5-base` 模型，另一个是专门针对摘要生成任务微调过的 `t5-base-cnn`。\n",
        "\n",
        "首先，我们将使用一个数据集，让两个模型分别生成摘要。通过比较生成的摘要，我们可以观察微调是否有效。换句话说，这一步我们只能确定两个模型的输出有显著差异，但还不知道谁更好。\n",
        "\n",
        "为了确定哪个模型生成的摘要更好，我们将使用一个名为 `cnn_dailymail` 的知名数据集（可通过 `datasets` 库获取）。该数据集包含人工撰写的**参考摘要**用于对比。我们将把两个模型生成的摘要与这些参考摘要进行评估。\n",
        "\n",
        "获得更高 ROUGE 分数的模型将被认为能产生更好的摘要。"
      ],
      "metadata": {
        "id": "A97Oplza1LhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 涉及的模型\n",
        "\n",
        "* **t5-Base 微调版**: `flax-community/t5-base-cnn-dm`\n",
        "* **t5-Base 原版**: `t5-base`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pp19O4wt1Rit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 环境安装与配置\n",
        "\n",
        "**中文适配说明**：为了演示中文评估，我们额外添加了 `jieba` 库用于中文分词。"
      ],
      "metadata": {
        "id": "BwV6k2LA1Trt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate\n",
        "!pip install -q transformers\n",
        "!pip install -q rouge_score\n",
        "!pip install -q kaggle\n",
        "!pip install -q datasets\n",
        "!pip install -q jieba"
      ],
      "metadata": {
        "id": "7Prvj_gJ1WsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import evaluate\n",
        "import nltk\n",
        "import jieba\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "ipjojm-j2fHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 加载数据\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# 获取密钥信息\n",
        "try:\n",
        "    # 从 Secrets 获取用户名和 Key\n",
        "    # 请确保你在 Secrets 里存的是 username 和 key\n",
        "    username = userdata.get('KAGGLE_USERNAME')\n",
        "    key = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "    # 创建配置目录\n",
        "    kaggle_dir = os.path.expanduser('~/.kaggle')\n",
        "    if not os.path.exists(kaggle_dir):\n",
        "        os.makedirs(kaggle_dir)\n",
        "\n",
        "    # 写入文件：构造 Kaggle CLI 能识别的标准格式\n",
        "    kaggle_json_path = os.path.join(kaggle_dir, 'kaggle.json')\n",
        "    with open(kaggle_json_path, 'w') as f:\n",
        "        json.dump({\"username\": username, \"key\": key}, f)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"错误：请检查 Colab Secrets 是否分别设置了 KAGGLE_USERNAME 和 KAGGLE_KEY。\")\n",
        "    raise e\n",
        "\n",
        "# 下载数据集\n",
        "print(\"正在下载数据集...\")\n",
        "# 使用 --force 覆盖下载，防止断点续传导致的错误\n",
        "!kaggle datasets download -d deepanshudalal09/mit-ai-news-published-till-2023 --force\n",
        "\n",
        "# 解压文件\n",
        "zip_file = \"mit-ai-news-published-till-2023.zip\"\n",
        "extract_path = \"./kaggle_data\"\n",
        "\n",
        "print(\"正在解压...\")\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# 4: 读取并处理数据\n",
        "csv_path = f\"{extract_path}/articles.csv\"\n",
        "\n",
        "news = pd.read_csv(csv_path)\n",
        "\n",
        "DOCUMENT = \"Article Body\"\n",
        "MAX_NEWS = 3\n",
        "articles = news.head(MAX_NEWS)[DOCUMENT].tolist()\n",
        "\n",
        "print(f\"\\n数据加载完毕！成功读取 {len(articles)} 条新闻。\")\n",
        "print(f\"第一条预览: {articles[0][:100]}...\")"
      ],
      "metadata": {
        "id": "5N4EaHV-557E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 加载模型并创建摘要\n",
        "\n",
        "这两个模型都在 Hugging Face 上可用。"
      ],
      "metadata": {
        "id": "SriobGXx786t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_base = \"t5-base\"\n",
        "model_name_finetuned = \"flax-community/t5-base-cnn-dm\"\n",
        "\n",
        "# 获取分词器和模型的辅助函数\n",
        "def get_model(model_id):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "    return tokenizer, model\n",
        "\n",
        "# 加载两个模型\n",
        "tokenizer_base, model_base = get_model(model_name_base)\n",
        "tokenizer_finetuned, model_finetuned = get_model(model_name_finetuned)"
      ],
      "metadata": {
        "id": "hiRIBwwt78MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义生成摘要的函数："
      ],
      "metadata": {
        "id": "pPbQhj_q_DVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summaries(texts_list, tokenizer, model, max_l=125):\n",
        "    # 我们给每篇文章加个前缀，告诉 T5 模型要做什么任务\n",
        "    prefix = \"Summarize this news: \"\n",
        "    summaries_list = []\n",
        "\n",
        "    texts_list = [prefix + text for text in texts_list]\n",
        "\n",
        "    for text in texts_list:\n",
        "        summary = \"\"\n",
        "        # 计算编码\n",
        "        input_encodings = tokenizer(text,\n",
        "                       max_length=1024,\n",
        "                       return_tensors='pt',\n",
        "                       padding=True,\n",
        "                       truncation=True\n",
        "                  )\n",
        "        # 生成摘要\n",
        "        start = time.time()\n",
        "        output = model.generate(\n",
        "            input_ids=input_encodings.input_ids,\n",
        "            attention_mask=input_encodings.attention_mask,\n",
        "            max_length=max_l,  # 设置生成摘要的最大长度\n",
        "            num_beams=2,       # 设置束搜索（beam search）的数量\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # 解码获取文本\n",
        "        summary = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
        "        end = time.time()\n",
        "\n",
        "        elapsed_time = end - start\n",
        "        print(f\"耗时: {elapsed_time:.3f} 秒\")\n",
        "        summaries_list += summary\n",
        "    return summaries_list"
      ],
      "metadata": {
        "id": "1Q9RzAlL_Get"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分别使用两个模型生成摘要："
      ],
      "metadata": {
        "id": "d-cJdnoDAV8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 使用基础模型生成 ---\")\n",
        "summaries_base = create_summaries(articles, tokenizer_base, model_base)\n",
        "\n",
        "print(\"\\n--- 使用微调模型生成 ---\")\n",
        "summaries_finetuned = create_summaries(articles, tokenizer_finetuned, model_finetuned)"
      ],
      "metadata": {
        "id": "nrT6yRWqAY17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看结果对比："
      ],
      "metadata": {
        "id": "DYHHQ0ioA3RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"基础模型摘要:\", summaries_base)\n",
        "print(\"微调模型摘要:\", summaries_finetuned)"
      ],
      "metadata": {
        "id": "P9-up86iA2y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "乍一看，摘要确实不同。但很难仅凭肉眼判断哪个更好。这就是我们需要 ROUGE 的原因。\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SSbOOAyYBAu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4. ROUGE 评估\n",
        "\n",
        "ROUGE 算法通常基于空格来切分单词（Tokens）。"
      ],
      "metadata": {
        "id": "Mp8YjfmWBFTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 加载 ROUGE"
      ],
      "metadata": {
        "id": "5jI_6EXqBS5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "_x2uWfB3BSEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 定义计算函数 (适配中文)\n",
        "\n",
        "下面的函数进行了修改，增加了 `is_chinese` 参数。如果是中文，会使用 `jieba` 进行分词并用空格连接，从而欺骗 ROUGE 算法使其能够正确处理中文。"
      ],
      "metadata": {
        "id": "jtKznYmOBVPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_rouge_score(generated, reference, is_chinese=False):\n",
        "    \"\"\"\n",
        "    计算 ROUGE 分数。\n",
        "    :param generated: 生成的摘要列表\n",
        "    :param reference: 参考摘要列表\n",
        "    :param is_chinese: 是否为中文文本 (如果是，将启用 Jieba 分词)\n",
        "    \"\"\"\n",
        "\n",
        "    # 预处理函数\n",
        "    def process_text(texts, is_zh):\n",
        "        processed = []\n",
        "        for s in texts:\n",
        "            s = s.strip()\n",
        "            if is_zh:\n",
        "                # 中文核心步骤：分词并用空格连接\n",
        "                # \"我爱AI\" -> \"我 爱 AI\"\n",
        "                tokens = jieba.cut(s)\n",
        "                processed.append(\" \".join(tokens))\n",
        "            else:\n",
        "                # 英文步骤：按句分割并换行 (Rouge 库的一般要求)\n",
        "                processed.append(\"\\n\".join(sent_tokenize(s)))\n",
        "        return processed\n",
        "\n",
        "    generated_processed = process_text(generated, is_chinese)\n",
        "    reference_processed = process_text(reference, is_chinese)\n",
        "\n",
        "    # 英文通常可以使用 stemmer (词干提取)，中文不需要\n",
        "    use_stemmer = not is_chinese\n",
        "\n",
        "    return rouge_score.compute(\n",
        "        predictions=generated_processed,\n",
        "        references=reference_processed,\n",
        "        use_stemmer=use_stemmer,\n",
        "    )"
      ],
      "metadata": {
        "id": "lM9Lh46YBf0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 比较两个模型的输出 (英文环境)\n",
        "\n",
        "这里我们比较 Base 模型和 Fine-tuned 模型的输出差异（注意：这里不是评估好坏，只是评估差异）。"
      ],
      "metadata": {
        "id": "1KQ5NGeOBrky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 这里是英文，所以 is_chinese=False\n",
        "scores = compute_rouge_score(summaries_base, summaries_finetuned, is_chinese=False)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "kOj8HDgRBtYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 结果分析：基础模型 vs 微调模型\n",
        "\n",
        "我们对比了 **基础模型 (t5-base)** 和 **微调模型 (t5-base-cnn)** 在同一篇新闻上生成的摘要。计算得出的 ROUGE 分数如下：\n",
        "\n",
        "* **ROUGE-1**: `0.47` (47%)\n",
        "* **ROUGE-2**: `0.32` (32%)\n",
        "* **ROUGE-L**: `0.34` (34%)\n",
        "\n",
        "#### 详细解读\n",
        "\n",
        "这一组数据揭示了微调（Fine-tuning）对模型产生的影响：**“核心内容一致，但表达风格迥异”。**\n",
        "\n",
        "**1. ROUGE-1 (0.47) —— 关键词高度重叠**\n",
        "\n",
        "* **含义**：衡量**单个词 (Unigrams)** 的重叠率。\n",
        "* **分析**：接近 **50%** 的词汇是相同的。这说明两个模型都没有跑题，都准确抓住了原文中的核心实体（如 *\"MIT\"*, *\"molecules\"*, *\"system\"*）。微调并没有丢失文章的核心事实。\n",
        "\n",
        "**2. ROUGE-2 (0.32) —— 遣词造句发生变化**\n",
        "\n",
        "* **含义**：衡量**双词短语 (Bigrams)** 的重叠率（即相邻的两个词是否一样）。\n",
        "* **分析**：分数相比 ROUGE-1 显著下降 (0.47 -> 0.32)。这意味着虽然大家用的“词”差不多，但**组合词的方式**变了。\n",
        "* *例子*：基础模型可能说 *\"predict molecular properties\"*，而微调模型说 *\"predict their properties\"*。意思一样，但短语不同。\n",
        "\n",
        "\n",
        "\n",
        "**3. ROUGE-L (0.34) —— 句式结构重构**\n",
        "\n",
        "* **含义**：衡量**最长公共子序列**，反映句子结构的相似度。\n",
        "* **分析**：**34%** 的分数表明两个模型的**句法结构**有明显差异。\n",
        "* 基础模型倾向于机械地拼接原文句子（陈述句）。\n",
        "* 微调模型学会了新闻报道的风格（例如使用 *\"Researchers created...\"* 作为主语），导致句子结构与基础模型不再对齐。\n",
        "\n",
        "\n",
        "\n",
        "> **结论**  \n",
        "> 这组数据证明微调是**有效**的：模型不仅仅是在复制基础模型的能力，它成功习得了新的**语言风格（News Style）**，同时保留了**核心信息准确性（High ROUGE-1）**。"
      ],
      "metadata": {
        "id": "df8R6R77B9ID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 与真实数据集对比 (评估质量)\n",
        "\n",
        "为了判断谁更好，我们需要与“标准答案”对比。我们将加载 `cnn_dailymail` 数据集。"
      ],
      "metadata": {
        "id": "Q7H4UqsmCUGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "print(\"正在加载 CNN/DailyMail 数据集...\")\n",
        "cnn_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "print(\"正在提取测试数据...\")\n",
        "sample_cnn = cnn_dataset[\"test\"].select(range(MAX_NEWS))\n",
        "\n",
        "real_articles = sample_cnn[\"article\"]\n",
        "real_summaries = sample_cnn[\"highlights\"]\n",
        "\n",
        "print(f\"成功加载测试数据！共 {len(real_articles)} 条。\")\n",
        "print(f\"第一条参考摘要预览: {real_summaries[0][:100]}...\")"
      ],
      "metadata": {
        "id": "OGLlXhraCWvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "让两个模型针对这些新闻生成摘要："
      ],
      "metadata": {
        "id": "IKWnZKXgCYn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取参考摘要的最大长度作为约束\n",
        "max_length = max(len(item) for item in real_summaries) + 10\n",
        "\n",
        "summaries_t5_base = create_summaries(real_articles, tokenizer_base, model_base, max_l=max_length)\n",
        "summaries_t5_finetuned = create_summaries(real_articles, tokenizer_finetuned, model_finetuned, max_l=max_length)"
      ],
      "metadata": {
        "id": "AjvdpgizHS9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = pd.DataFrame.from_dict(\n",
        "        {\n",
        "            \"base\": summaries_t5_base,\n",
        "            \"finetuned\": summaries_t5_finetuned,\n",
        "            \"reference\": real_summaries,\n",
        "        }\n",
        "    )\n",
        "summaries.head()"
      ],
      "metadata": {
        "id": "IXJTAb3vh_-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 计算 ROUGE 分数"
      ],
      "metadata": {
        "id": "0KTZlF22HUxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 基础模型 (Base) 真实得分 ---\")\n",
        "# 预测值：基础模型生成的摘要\n",
        "# 参考值：人工写的 Highlights\n",
        "score_base = compute_rouge_score(summaries_t5_base, real_summaries, is_chinese=False)\n",
        "print(score_base)\n",
        "\n",
        "# 3. 计算 微调模型 vs 标准答案\n",
        "print(\"\\n--- 微调模型 (Fine-tuned) 真实得分 ---\")\n",
        "# 预测值：微调模型生成的摘要\n",
        "# 参考值：人工写的 Highlights\n",
        "score_finetuned = compute_rouge_score(summaries_t5_finetuned, real_summaries, is_chinese=False)\n",
        "print(score_finetuned)"
      ],
      "metadata": {
        "id": "DpkLg7QfHWzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测了好几遍结果，基础模型的总结摘要比微调模型会更好一点，不理解哪里出问题了"
      ],
      "metadata": {
        "id": "asQnMExijCtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities=['Paris, Londres, Barcelona, Reus']\n",
        "entities_ref=['Reus, Paris, Londres, Barcelona']"
      ],
      "metadata": {
        "id": "9MYw8AeyjIYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_rouge_score(entities, entities_ref)"
      ],
      "metadata": {
        "id": "1FB-gToYjLa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_ref=['Paris, Londres, Barcelona, Reus']\n",
        "compute_rouge_score(entities, entities_ref)"
      ],
      "metadata": {
        "id": "clkdGy8TjMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9fniVGDjO1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}